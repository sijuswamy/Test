{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWNi12ug+DdKlfY9StpdHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sijuswamy/Test/blob/main/Quiz_2_Lab_Exam_Sample_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 24DL6111 Deep Learning\n",
        "\n",
        "Topics: Evaluation Metric for deep learning, CNN, RNN, LSTM and GRU"
      ],
      "metadata": {
        "id": "8GCwxOTnjRXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a python code to create a function to calculate output dimentsion and number of trainable parameters in a convolutional Layer."
      ],
      "metadata": {
        "id": "NNVOP7K1jiN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def conv_summary(input_shape, kernal_info,padding,stride):\n",
        "  input_h,input_w,input_c=input_shape\n",
        "  p=padding\n",
        "  s=stride\n",
        "  kernel_h,kernel_w,kernel_depth=kernal_info\n",
        "  output_h=int((input_h+2*p-kernel_h)/s+1)\n",
        "  output_w=int((input_w+2*p-kernel_w)/s+1)\n",
        "  output_depth=kernel_depth\n",
        "  total_tranable_param=(kernel_h*kernel_w*input_c+1)*output_depth\n",
        "  return (output_h,output_w,output_depth),total_tranable_param\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_DlctWTmk8Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value assignmnents\n",
        "input_shape=np.array([256,256,3])\n",
        "input_shape.shape\n",
        "kernal_info=np.array([4,4,64])\n",
        "padding=0\n",
        "stride=1\n",
        "# function calling\n",
        "od,param=conv_summary(input_shape,kernal_info,padding,stride)\n",
        "# printing outputs\n",
        "print('Output dimension',od)\n",
        "print('Trainable parameters:',param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx9JUsvemEHB",
        "outputId": "9680a277-15b6-41ca-c858-1db6b8c36042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output dimension (253, 253, np.int64(64))\n",
            "Trainable parameters: 3136\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# do the same with keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Import Sequential and other layers directly from tensorflow.keras.layers\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU,Conv2D"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oyS9qG_GrnCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(64,(4,4),padding='valid',strides=(1,1),activation='relu',input_shape=(256,256,3)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_vlYd6G5sDsJ",
        "outputId": "37f43c85-b895-4850-e81d-ffe39e4a1d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m3,136\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,136\u001b[0m (12.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> (12.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,136\u001b[0m (12.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> (12.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create a simple RNN using numpy"
      ],
      "metadata": {
        "id": "vl5XwQVss9BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN_calc(W_R,X_t,w_x,h_t,b_R,b_y):\n",
        "   h_t=np.tanh(np.dot(W_R,h_t)+np.dot(w_x,x_t)+b_R)\n",
        "   y_t=np.tanh(np.dot(W_x,x_t.T)+b_y)\n",
        "   return h_t,y_t\n",
        "\n",
        "W_R=np.array([[0.1,0.2],[0.7,0.9]])\n",
        "W_x=np.array([[1,0]])\n",
        "b_R=0.5\n",
        "b_y=0.4\n",
        "x_t=np.array([1,0])\n",
        "h_t=np.array([0.1,0.2])\n",
        "h,y_t=RNN_calc(W_R,x_t,W_x,h_t,b_R,b_y)\n",
        "print(h,y_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeFriBrZtBYa",
        "outputId": "9742cd80-9ad5-4b55-8087-2560c0964721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91378549 0.94137554] [0.88535165]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Do the same with keras"
      ],
      "metadata": {
        "id": "dUNJLePOvK0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnnModel=Sequential()\n",
        "rnnModel.add(SimpleRNN(1,input_shape=(1,2)))\n",
        "rnnModel.summary()\n",
        "rnnModel.compile(optimizer='adam',loss='mse')\n",
        "rnnModel.fit(x_t.reshape(1,1,2),y_t.reshape(1,2),epochs=100) #(1=number of samples, 1= sequence length, 2= number of features)\n"
      ],
      "metadata": {
        "id": "BDPLofU6vOyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict output\n",
        "rnnModel.predict(np.array([9,10]).reshape(1,1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP-wcd5BxJav",
        "outputId": "401a3a1c-588b-44a9-baf9-ad4eb9c7a714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.96182984]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a python code to simulate the prediction of next term using an RNN"
      ],
      "metadata": {
        "id": "wJm6QRrAXvw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize weights and biases\n",
        "def initialize_rnn(input_size, hidden_size):\n",
        "    Wxh = np.random.randn(hidden_size, input_size) * 0.01  # Input to hidden\n",
        "    Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # Hidden to hidden\n",
        "    Why = np.random.randn(1, hidden_size) * 0.01  # Hidden to output\n",
        "    bh = np.zeros((hidden_size, 1))  # Hidden bias\n",
        "    by = np.zeros((1, 1))  # Output bias\n",
        "    return Wxh, Whh, Why, bh, by\n",
        "\n",
        "# Forward pass through the RNN\n",
        "def forward_rnn(inputs, Wxh, Whh, Why, bh, by, hprev):\n",
        "    hs = {}\n",
        "    ys = {}\n",
        "    hs[-1] = np.copy(hprev)\n",
        "\n",
        "    for t in range(len(inputs)):\n",
        "        # Convert the input element to a NumPy array before reshaping\n",
        "        hs[t] = np.tanh(np.dot(Wxh, np.array(inputs[t]).reshape(-1, 1)) +\n",
        "                        np.dot(Whh, hs[t-1]) + bh)\n",
        "        ys[t] = np.dot(Why, hs[t]) + by\n",
        "\n",
        "    return ys, hs\n",
        "\n",
        "# Predict the next value in the sequence\n",
        "def predict_next_rnn(inputs, Wxh, Whh, Why, bh, by, hidden_size):\n",
        "    hprev = np.zeros((hidden_size, 1))\n",
        "    ys, _ = forward_rnn(inputs, Wxh, Whh, Why, bh, by, hprev)\n",
        "    return ys[len(inputs)-1]\n",
        "\n",
        "# Example usage\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "\n",
        "# Initialize weights and biases\n",
        "Wxh, Whh, Why, bh, by = initialize_rnn(input_size, hidden_size)\n",
        "\n",
        "# Define a sequence\n",
        "sequence = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Predict the next value\n",
        "predicted_value = predict_next_rnn(sequence, Wxh, Whh, Why, bh, by, hidden_size)\n",
        "\n",
        "print(\"Predicted next value:\", predicted_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAP88UcX6_0",
        "outputId": "c9ee6ecc-3528-47af-ac7a-fb2c318db5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next value: [[0.00053992]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "# Define a simple RNN model\n",
        "def create_rnn_model(input_size, hidden_size):\n",
        "    model = Sequential([\n",
        "        SimpleRNN(hidden_size, input_shape=(None, input_size), return_sequences=True),\n",
        "        Dense(1)  # Output layer to predict a scalar value\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "sequence_length = 5\n",
        "\n",
        "# Create the RNN model\n",
        "rnn_model = create_rnn_model(input_size, hidden_size)\n",
        "\n",
        "# Generate a sample sequence\n",
        "sequence = np.array([[1], [2], [3], [4], [5]])  # Shape: (sequence_length, input_size)\n",
        "sequence = np.expand_dims(sequence, axis=0)  # Shape: (1, sequence_length, input_size)\n",
        "\n",
        "# Predict the next value\n",
        "predicted_value = rnn_model.predict(sequence)\n",
        "print(\"Predicted next value:\", predicted_value[:, -1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9xDgSDnYflN",
        "outputId": "f4ad77be-754f-4d75-b237-bb8501064b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "Predicted next value: [[-0.9595526]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Simulate the calculations in an LSTM"
      ],
      "metadata": {
        "id": "phkmZ_ZoIUWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Tanh activation function\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Initialize LSTM weights and biases\n",
        "def initialize_lstm(input_size, hidden_size):\n",
        "    # Input to hidden weights\n",
        "    Wf = np.random.randn(hidden_size, input_size) * 0.01  # Forget gate\n",
        "    Wi = np.random.randn(hidden_size, input_size) * 0.01  # Input gate\n",
        "    Wo = np.random.randn(hidden_size, input_size) * 0.01  # Output gate\n",
        "    Wc = np.random.randn(hidden_size, input_size) * 0.01  # Candidate cell state\n",
        "\n",
        "    # Hidden to hidden weights\n",
        "    Uf = np.random.randn(hidden_size, hidden_size) * 0.01  # Forget gate\n",
        "    Ui = np.random.randn(hidden_size, hidden_size) * 0.01  # Input gate\n",
        "    Uo = np.random.randn(hidden_size, hidden_size) * 0.01  # Output gate\n",
        "    Uc = np.random.randn(hidden_size, hidden_size) * 0.01  # Candidate cell state\n",
        "\n",
        "    # Biases\n",
        "    bf = np.zeros((hidden_size, 1))  # Forget gate bias\n",
        "    bi = np.zeros((hidden_size, 1))  # Input gate bias\n",
        "    bo = np.zeros((hidden_size, 1))  # Output gate bias\n",
        "    bc = np.zeros((hidden_size, 1))  # Candidate cell state bias\n",
        "\n",
        "    # Output layer weights and biases (maps hidden state to scalar output)\n",
        "    Wy = np.random.randn(1, hidden_size) * 0.01  # Maps hidden state to scalar output\n",
        "    by = np.zeros((1, 1))  # Bias for the output layer\n",
        "\n",
        "    return Wf, Wi, Wo, Wc, Uf, Ui, Uo, Uc, bf, bi, bo, bc, Wy, by\n",
        "\n",
        "# Forward pass through the LSTM\n",
        "def forward_lstm(inputs, Wf, Wi, Wo, Wc, Uf, Ui, Uo, Uc, bf, bi, bo, bc, Wy, by, hprev, cprev):\n",
        "    hs = {}\n",
        "    cs = {}\n",
        "    ys = {}\n",
        "    hs[-1] = np.copy(hprev)\n",
        "    cs[-1] = np.copy(cprev)\n",
        "\n",
        "    for t in range(len(inputs)):\n",
        "        # Convert the input element to a NumPy array before reshaping\n",
        "        xt = np.array(inputs[t]).reshape(-1, 1)\n",
        "\n",
        "        # Forget gate\n",
        "        ft = sigmoid(np.dot(Wf, xt) + np.dot(Uf, hs[t-1]) + bf)\n",
        "\n",
        "        # Input gate\n",
        "        it = sigmoid(np.dot(Wi, xt) + np.dot(Ui, hs[t-1]) + bi)\n",
        "\n",
        "        # Candidate cell state\n",
        "        ct_hat = tanh(np.dot(Wc, xt) + np.dot(Uc, hs[t-1]) + bc)\n",
        "\n",
        "        # Cell state update\n",
        "        cs[t] = ft * cs[t-1] + it * ct_hat\n",
        "\n",
        "        # Output gate\n",
        "        ot = sigmoid(np.dot(Wo, xt) + np.dot(Uo, hs[t-1]) + bo)\n",
        "\n",
        "        # Hidden state update\n",
        "        hs[t] = ot * tanh(cs[t])\n",
        "\n",
        "        # Output calculation (apply linear transformation to hidden state)\n",
        "        ys[t] = np.dot(Wy, hs[t]) + by\n",
        "\n",
        "    return ys, hs, cs\n",
        "\n",
        "# Predict the next value in the sequence\n",
        "def predict_next_lstm(inputs, Wf, Wi, Wo, Wc, Uf, Ui, Uo, Uc, bf, bi, bo, bc, Wy, by, hidden_size):\n",
        "    hprev = np.zeros((hidden_size, 1))\n",
        "    cprev = np.zeros((hidden_size, 1))\n",
        "    ys, _, _ = forward_lstm(inputs, Wf, Wi, Wo, Wc, Uf, Ui, Uo, Uc, bf, bi, bo, bc, Wy, by, hprev, cprev)\n",
        "    return ys[len(inputs)-1]\n",
        "\n",
        "# Example usage\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "\n",
        "# Initialize weights and biases\n",
        "Wf, Wi, Wo, Wc, Uf, Ui, Uo, Uc, bf, bi, bo, bc, Wy, by = initialize_lstm(input_size, hidden_size)\n",
        "\n",
        "# Define a sequence\n",
        "sequence = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Predict the next value\n",
        "predicted_value = predict_next_lstm(sequence, Wf, Wi, Wo, Wc, Uf, Ui, Uo, Uc, bf, bi, bo, bc, Wy, by, hidden_size)\n",
        "\n",
        "print(\"Predicted next value:\", predicted_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsevc0MWIZuv",
        "outputId": "8a38e030-f6b5-4304-fcfe-6552cc3dca9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "Predicted next value: [[1.0070797]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Define a simple LSTM model\n",
        "def create_lstm_model(input_size, hidden_size):\n",
        "    model = Sequential([\n",
        "        LSTM(hidden_size, input_shape=(None, input_size), return_sequences=True),\n",
        "        Dense(1)  # Output layer to predict a scalar value\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "sequence_length = 5\n",
        "\n",
        "# Create the LSTM model\n",
        "lstm_model = create_lstm_model(input_size, hidden_size)\n",
        "\n",
        "# Generate a sample sequence\n",
        "sequence = np.array([[1], [2], [3], [4], [5]])  # Shape: (sequence_length, input_size)\n",
        "sequence = np.expand_dims(sequence, axis=0)  # Shape: (1, sequence_length, input_size)\n",
        "\n",
        "# Predict the next value\n",
        "predicted_value = lstm_model.predict(sequence)\n",
        "print(\"Predicted next value:\", predicted_value[:, -1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMcWMcjvfNEu",
        "outputId": "ddab881f-3aca-4586-bc6e-206ae62ab243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79d841f7b920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "Predicted next value: [[-0.40329558]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Preciting next value with GRU"
      ],
      "metadata": {
        "id": "ooye_TnmbJpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Tanh activation function\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Initialize GRU weights and biases\n",
        "def initialize_gru(input_size, hidden_size):\n",
        "    # Input to hidden weights\n",
        "    Wz = np.random.randn(hidden_size, input_size) * 0.01  # Update gate\n",
        "    Wr = np.random.randn(hidden_size, input_size) * 0.01  # Reset gate\n",
        "    Wh = np.random.randn(hidden_size, input_size) * 0.01  # Hidden state candidate\n",
        "\n",
        "    # Hidden to hidden weights\n",
        "    Uz = np.random.randn(hidden_size, hidden_size) * 0.01  # Update gate\n",
        "    Ur = np.random.randn(hidden_size, hidden_size) * 0.01  # Reset gate\n",
        "    Uh = np.random.randn(hidden_size, hidden_size) * 0.01  # Hidden state candidate\n",
        "\n",
        "    # Biases\n",
        "    bz = np.zeros((hidden_size, 1))  # Update gate bias\n",
        "    br = np.zeros((hidden_size, 1))  # Reset gate bias\n",
        "    bh = np.zeros((hidden_size, 1))  # Hidden state candidate bias\n",
        "\n",
        "    # Output layer weights and biases (maps hidden state to scalar output)\n",
        "    Wy = np.random.randn(1, hidden_size) * 0.01  # Maps hidden state to scalar output\n",
        "    by = np.zeros((1, 1))  # Bias for the output layer\n",
        "\n",
        "    return Wz, Wr, Wh, Uz, Ur, Uh, bz, br, bh, Wy, by\n",
        "\n",
        "# Forward pass through the GRU\n",
        "def forward_gru(inputs, Wz, Wr, Wh, Uz, Ur, Uh, bz, br, bh, Wy, by, hprev):\n",
        "    hs = {}\n",
        "    ys = {}\n",
        "    hs[-1] = np.copy(hprev)\n",
        "\n",
        "    for t in range(len(inputs)):\n",
        "        # Convert the input element to a NumPy array before reshaping\n",
        "        xt = np.array(inputs[t]).reshape(-1, 1)\n",
        "\n",
        "        # Update gate\n",
        "        zt = sigmoid(np.dot(Wz, xt) + np.dot(Uz, hs[t-1]) + bz)\n",
        "\n",
        "        # Reset gate\n",
        "        rt = sigmoid(np.dot(Wr, xt) + np.dot(Ur, hs[t-1]) + br)\n",
        "\n",
        "        # Candidate hidden state\n",
        "        ht_hat = tanh(np.dot(Wh, xt) + np.dot(Uh, rt * hs[t-1]) + bh)\n",
        "\n",
        "        # Hidden state update\n",
        "        hs[t] = (1 - zt) * hs[t-1] + zt * ht_hat\n",
        "\n",
        "        # Output calculation (apply linear transformation to hidden state)\n",
        "        ys[t] = np.dot(Wy, hs[t]) + by\n",
        "\n",
        "    return ys, hs\n",
        "\n",
        "# Predict the next value in the sequence\n",
        "def predict_next_gru(inputs, Wz, Wr, Wh, Uz, Ur, Uh, bz, br, bh, Wy, by, hidden_size):\n",
        "    hprev = np.zeros((hidden_size, 1))\n",
        "    ys, _ = forward_gru(inputs, Wz, Wr, Wh, Uz, Ur, Uh, bz, br, bh, Wy, by, hprev)\n",
        "    return ys[len(inputs)-1]\n",
        "\n",
        "# Example usage\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "\n",
        "# Initialize weights and biases\n",
        "Wz, Wr, Wh, Uz, Ur, Uh, bz, br, bh, Wy, by = initialize_gru(input_size, hidden_size)\n",
        "\n",
        "# Define a sequence\n",
        "sequence = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Predict the next value\n",
        "predicted_value = predict_next_gru(sequence, Wz, Wr, Wh, Uz, Ur, Uh, bz, br, bh, Wy, by, hidden_size)\n",
        "\n",
        "print(\"Predicted next value:\", predicted_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK6R6MfFbPH_",
        "outputId": "9f481070-2cfe-48c7-cdaa-0cf0b615a4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next value: [[1.6776319e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "\n",
        "# Define a simple GRU model\n",
        "def create_gru_model(input_size, hidden_size):\n",
        "    model = Sequential([\n",
        "        GRU(hidden_size, input_shape=(None, input_size), return_sequences=True),\n",
        "        Dense(1)  # Output layer to predict a scalar value\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "sequence_length = 5\n",
        "\n",
        "# Create the GRU model\n",
        "gru_model = create_gru_model(input_size, hidden_size)\n",
        "\n",
        "# Generate a sample sequence\n",
        "sequence = np.array([[1], [2], [3], [4], [5]])  # Shape: (sequence_length, input_size)\n",
        "sequence = np.expand_dims(sequence, axis=0)  # Shape: (1, sequence_length, input_size)\n",
        "\n",
        "# Predict the next value\n",
        "predicted_value = gru_model.predict(sequence)\n",
        "print(\"Predicted next value:\", predicted_value[:, -1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3p2ddf_fRBa",
        "outputId": "59a5ea3c-890f-49ed-9398-184979b56adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "Predicted next value: [[0.06169859]]\n"
          ]
        }
      ]
    }
  ]
}