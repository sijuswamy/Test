{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sijuswamy/Test/blob/main/Car_parts_segmentation_example_yolo11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carparts Segmentation using Ultralytics YOLO11\n",
        "\n",
        "This notebook serves as a starting point for training the YOLO11 model on [carparts](https://docs.ultralytics.com/datasets/segment/carparts-seg/) segmentation dataset."
      ],
      "metadata": {
        "id": "7EM2nwU4jshF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Structure\n",
        "\n",
        "The data distribution within the Carparts Segmentation Dataset is organized as outlined below:\n",
        "\n",
        "- **Training set**: Includes 3156 images, each accompanied by its corresponding annotations.\n",
        "- **Testing set**: Comprises 276 images, with each one paired with its respective annotations.\n",
        "- **Validation set**: Consists of 401 images, each having corresponding annotations."
      ],
      "metadata": {
        "id": "xypoYW_oYZAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "\n",
        "Carparts Segmentation finds applications in automotive quality control, auto repair, e-commerce cataloging, traffic monitoring, autonomous vehicles, insurance processing, recycling, and smart city initiatives. It streamlines processes by accurately identifying and categorizing different vehicle components, contributing to efficiency and automation in various industries."
      ],
      "metadata": {
        "id": "R4SICbq5Yalg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "outputId": "824aadeb-2b9f-4bcf-8e5e-737bb4ebc607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.94 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 41.1/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset YAML File\n",
        "\n",
        "A YAML (Yet Another Markup Language) file defines the dataset configuration, including paths, classes, and other pertinent details. üòÄ"
      ],
      "metadata": {
        "id": "xE6ntKojSfSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```yaml\n",
        "# Ultralytics YOLO üöÄ, AGPL-3.0 license\n",
        "# Carparts-seg dataset by Ultralytics\n",
        "# Documentation: https://docs.ultralytics.com/datasets/segment/carparts-seg/\n",
        "# Example usage: yolo train data=carparts-seg.yaml\n",
        "# parent\n",
        "# ‚îú‚îÄ‚îÄ ultralytics\n",
        "# ‚îî‚îÄ‚îÄ datasets\n",
        "#     ‚îî‚îÄ‚îÄ carparts-seg  ‚Üê downloads here (132 MB)\n",
        "\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: ../datasets/carparts-seg # dataset root dir\n",
        "train: train/images # train images (relative to 'path') 3516 images\n",
        "val: valid/images # val images (relative to 'path') 276 images\n",
        "test: test/images # test images (relative to 'path') 401 images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: back_bumper\n",
        "  1: back_door\n",
        "  2: back_glass\n",
        "  3: back_left_door\n",
        "  4: back_left_light\n",
        "  5: back_light\n",
        "  6: back_right_door\n",
        "  7: back_right_light\n",
        "  8: front_bumper\n",
        "  9: front_door\n",
        "  10: front_glass\n",
        "  11: front_left_door\n",
        "  12: front_left_light\n",
        "  13: front_light\n",
        "  14: front_right_door\n",
        "  15: front_right_light\n",
        "  16: hood\n",
        "  17: left_mirror\n",
        "  18: object\n",
        "  19: right_mirror\n",
        "  20: tailgate\n",
        "  21: trunk\n",
        "  22: wheel\n",
        "\n",
        "# Download script/URL (optional)\n",
        "download: https://github.com/ultralytics/assets/releases/download/v0.0.0/carparts-seg.zip\n",
        "```"
      ],
      "metadata": {
        "id": "h8go3HNgN0WU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ],
      "metadata": {
        "id": "fMV-sNfiSt_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-seg.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=\"carparts-seg.yaml\", epochs=10, imgsz=640, batch=32, workers=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgMYUvlNLvy",
        "outputId": "2d598342-2d86-4345-e285-0e6b6101df96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.90M/5.90M [00:00<00:00, 122MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.94 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=carparts-seg.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=64, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
            "\n",
            "Dataset 'carparts-seg.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/carparts-seg/valid/images'\n",
            "Downloading https://ultralytics.com/assets/carparts-seg.zip to '/content/datasets/carparts-seg.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 133M/133M [00:02<00:00, 61.4MB/s]\n",
            "Unzipping /content/datasets/carparts-seg.zip to /content/datasets/carparts-seg...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7671/7671 [00:02<00:00, 3503.88file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (5.5s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 24.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=23\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    687925  ultralytics.nn.modules.head.Segment          [23, 32, 64, [64, 128, 256]]  \n",
            "YOLO11n-seg summary: 203 layers, 2,847,093 parameters, 2,847,077 gradients, 10.4 GFLOPs\n",
            "\n",
            "Transferred 510/561 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 88.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/carparts-seg/train/labels... 3156 images, 116 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3156/3156 [00:02<00:00, 1441.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/carparts-seg/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/carparts-seg/valid/labels... 401 images, 12 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 401/401 [00:00<00:00, 660.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/carparts-seg/valid/labels.cache\n",
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00037, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      5.72G      1.329      2.778      4.077      1.484        110        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:21<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042       0.91     0.0541      0.119     0.0837      0.911     0.0543       0.12      0.081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      6.93G      1.058      1.917      2.504      1.222        106        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:12<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.429      0.462      0.343       0.25       0.41      0.455       0.34      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      6.97G     0.9427      1.669      1.671      1.141         86        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:12<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.485      0.518      0.473      0.345      0.488      0.519      0.477      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      6.97G     0.8682      1.523      1.375      1.086         99        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:11<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.504      0.623      0.536      0.416      0.508      0.629      0.545      0.396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      6.99G     0.8238      1.413      1.218       1.05         99        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:13<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.451      0.634      0.539      0.422       0.45      0.631      0.543      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10         7G     0.7759      1.309      1.097      1.026        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:11<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.532      0.708      0.632        0.5      0.533      0.707      0.638      0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      7.02G     0.7408       1.26      1.025      1.004         83        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:11<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.582      0.721      0.633      0.514      0.587      0.724      0.641       0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      7.03G     0.7105      1.197     0.9494     0.9861         93        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:11<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.574      0.768      0.656      0.529      0.574      0.766      0.658       0.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      7.06G     0.6789      1.144     0.8993     0.9689        121        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:10<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042      0.518      0.773      0.611      0.499      0.517      0.774       0.62      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      7.06G     0.6521      1.104     0.8593     0.9572         90        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [01:09<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042       0.59      0.805      0.669      0.548      0.583      0.806      0.678      0.529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.225 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.94 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-seg summary (fused): 113 layers, 2,839,053 parameters, 0 gradients, 10.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  14%|‚ñà‚ñç        | 1/7 [00:01<00:10,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  29%|‚ñà‚ñà‚ñä       | 2/7 [00:09<00:26,  5.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ‚ö†Ô∏è Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:30<00:00,  4.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        401       2042       0.59      0.805      0.669      0.548      0.583      0.806      0.678      0.528\n",
            "           back_bumper         94         94      0.857      0.947      0.933      0.753      0.853      0.947      0.932      0.679\n",
            "             back_door        158        159      0.763      0.931      0.912       0.79      0.758      0.943       0.91      0.756\n",
            "            back_glass        114        115      0.817      0.939      0.931       0.78      0.807       0.93      0.919      0.761\n",
            "        back_left_door         15         15       0.52      0.867      0.553      0.489      0.517      0.867      0.553      0.439\n",
            "       back_left_light         19         19      0.435      0.684      0.538       0.38      0.441      0.707      0.532      0.371\n",
            "            back_light        161        226      0.741       0.85      0.825        0.6      0.741      0.863      0.833      0.576\n",
            "       back_right_door         12         12      0.443      0.833      0.563       0.47      0.427      0.833      0.563       0.45\n",
            "      back_right_light         13         13      0.403      0.846      0.587      0.474      0.389      0.846      0.587      0.475\n",
            "          front_bumper        208        208      0.894      0.995      0.951      0.871      0.892      0.996      0.951      0.845\n",
            "            front_door        167        167      0.804      0.976      0.909      0.799        0.8      0.976      0.909      0.782\n",
            "           front_glass        214        214      0.938      0.986      0.974        0.9      0.935      0.986      0.974      0.896\n",
            "       front_left_door         15         15      0.479      0.933      0.661      0.596      0.477      0.933      0.661      0.533\n",
            "      front_left_light         30         30      0.486        0.7      0.552      0.395       0.48      0.708      0.552      0.394\n",
            "           front_light        248        373      0.827      0.906      0.888      0.672      0.822      0.912      0.891       0.65\n",
            "      front_right_door         12         12      0.435      0.917      0.414      0.345      0.431      0.917      0.414      0.302\n",
            "     front_right_light         26         26      0.464      0.769       0.57      0.445       0.46      0.769       0.57      0.449\n",
            "                  hood        214        214      0.901      0.975      0.948      0.834      0.898      0.977      0.948      0.835\n",
            "           left_mirror         31         31      0.461      0.613      0.437      0.305      0.453      0.613      0.437      0.278\n",
            "                object          1          1          0          0          0          0          0          0          0          0\n",
            "          right_mirror         31         31      0.514       0.71      0.528      0.341      0.514      0.717      0.528      0.355\n",
            "              tailgate          5          5      0.437        0.8      0.686      0.587      0.423        0.8      0.777       0.62\n",
            "                 trunk          9          9      0.486      0.778      0.602      0.479      0.407      0.667      0.532      0.401\n",
            "                 wheel         34         53      0.461      0.566      0.431      0.308      0.483      0.623      0.622      0.303\n",
            "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 11.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dataset sample image](https://github.com/ultralytics/docs/releases/download/0/dataset-sample-image.avif)"
      ],
      "metadata": {
        "id": "_Hapx6WkS--T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a yolo command for a variety of tasks and modes and accepts additional arguments, i.e. imgsz=640. See a full list of available [yolo arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ],
      "metadata": {
        "id": "mKAUvDAbTEjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/runs/segment/train/weights/best.pt\")  # load a fine-tuned model\n",
        "\n",
        "# Inference using the model (img/video/stream)\n",
        "results = model.predict(\"https://github.com/ultralytics/assets/releases/download/v0.0.0/carparts-image.jpg\", save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzTbeqK_TB6t",
        "outputId": "40211052-e1e1-49ec-c215-9b5d999c3cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading https://ultralytics.com/assets/carparts-image.jpg to 'carparts-image.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 336k/336k [00:00<00:00, 12.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1 /content/carparts-image.jpg: 384x640 1 front_bumper, 1 front_glass, 1 front_left_door, 2 front_left_lights, 1 front_right_door, 1 front_right_light, 1 hood, 1 right_mirror, 5 wheels, 67.9ms\n",
            "Speed: 2.5ms preprocess, 67.9ms inference, 28.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/436ded05-9203-4bb7-883b-f7a1f9a399c1\" width=\"600\">"
      ],
      "metadata": {
        "id": "lmNKY3rWWsvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export\n",
        "\n",
        "Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | ‚úÖ        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | ‚úÖ        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | ‚ùå        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | ‚úÖ        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | ‚úÖ        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | ‚úÖ        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolov8n_imx_model/`      | ‚úÖ        | `imgsz`, `int8`                                                      |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo11n_rknn_model/`     | ‚úÖ        | `imgsz`, `batch`, `name`                                             |"
      ],
      "metadata": {
        "id": "vWBYYdXhTkN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/path/to/best.pt\")  # load a custom trained model\n",
        "\n",
        "# Export the model\n",
        "model.export(format=\"onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "S4nWG40CTlOD",
        "outputId": "c727cbf1-7fad-4c32-9872-2501309e765f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.58 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,839,053 parameters, 0 gradients, 10.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/segment/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 59, 8400), (1, 32, 160, 160)) (5.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.47...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.7s, saved as '/content/runs/segment/train/weights/best.onnx' (11.1 MB)\n",
            "\n",
            "Export complete (4.6s)\n",
            "Results saved to \u001b[1m/content/runs/segment/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=segment model=/content/runs/segment/train/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=segment model=/content/runs/segment/train/weights/best.onnx imgsz=640 data=/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/datasets/carparts-seg.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/runs/segment/train/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}